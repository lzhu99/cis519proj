{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CIS5190 Final Project ---- Stock Price Prediction\n",
        "By Xinyu Cai, Wanqing Ding and Leila Zhu<br>\n",
        "April 22nd, 2023"
      ],
      "metadata": {
        "id": "XBvylHZyQDcK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3s9TtclgC78"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime as dt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.express as px\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "%matplotlib inline\n",
        "\n",
        "# For time stamps\n",
        "from datetime import datetime\n",
        "\n",
        "# Model import\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM, GRU\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "#ARIMA Model\n",
        "import statsmodels.graphics.tsaplots as sgt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**I. Stock Price Data**\n",
        "[Link to CSV](https://www.kaggle.com/code/ysthehurricane/advanced-stock-pred-using-svr-rfr-knn-lstm-gru/input)"
      ],
      "metadata": {
        "id": "3e22VgE6Qiwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Data Loading and Basic Preprocessing"
      ],
      "metadata": {
        "id": "_mKpQc7_Q1K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unhashtag to install PyDrive install once\n",
        "#!pip install -U -q PyDrive\n",
        "\n",
        "#import dataset from GoogleDrive set up\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#please authenticate.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#files should be accessible using berkeley.edu\n",
        "stock_link = 'https://drive.google.com/file/d/1bKGOTVhOuAAv7D1iD0F2lOkm7YrRMOJU/view?usp=share_link'\n",
        "downloaded = drive.CreateFile({'id':\"1bKGOTVhOuAAv7D1iD0F2lOkm7YrRMOJU\"}) \n",
        "downloaded.GetContentFile('RELIANCE.csv')  \n",
        "df = pd.read_csv('RELIANCE.csv')"
      ],
      "metadata": {
        "id": "ZdP05WggmQEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset consists of historical stock prices for a particular company. The data covers a period from 08/19/2020 to 08/18/2021 and includes information on the opening, closing, high, and low prices for the stock, as well as the volume of shares traded on each day. Additionally, the dataset includes information on the adjusted close price, which takes into account any dividends or stock splits that may have occurred during the time period. "
      ],
      "metadata": {
        "id": "McPlDLM3ixCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sneak peak at the data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zGjE0RUBg-zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "I1UZ0xcahGWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "dju1zFc1jyjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Date.min()"
      ],
      "metadata": {
        "id": "eHN95ilLJrjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Date.max()"
      ],
      "metadata": {
        "id": "MCoB0YVFJm4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Data Preprocessing"
      ],
      "metadata": {
        "id": "n7ZSbO_D-BA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Null Values"
      ],
      "metadata": {
        "id": "NEY8n2iT-Jn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking null value\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Kndq2XAVDoEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the info table and checking null values above, we can see that all columns have 1 row of `NaN` values except the Date column. In fact, there are only 1 row of missing value in the entire dataframe! We are going to drop this one row, so that information we kept is still complete and essential. We procede by dropping the missing value rows."
      ],
      "metadata": {
        "id": "R6bO_GIwjaNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df.isna().any()"
      ],
      "metadata": {
        "id": "EgqoJOy-Dp9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Date from String to Date format in order for the modeling part."
      ],
      "metadata": {
        "id": "Ffjcxisxj01b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert date field from string to Date format and make it index\n",
        "df['Date'] = pd.to_datetime(df.Date)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HuY8qLT2j8GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**II. EDA**"
      ],
      "metadata": {
        "id": "ztZEyeWjii0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Data Visualization"
      ],
      "metadata": {
        "id": "0QILCye7ik3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Close Price"
      ],
      "metadata": {
        "id": "oJ1qU9eZkEml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The closing price of a stock is the final price at which the stock is traded during a specific trading day. It represents the market's consensus value of a stock at the end of the trading session. Investors and financial analysts often use the closing price as a reference point for assessing the stock's performance over time, comparing it to previous closing prices to analyze trends and make investment decisions."
      ],
      "metadata": {
        "id": "E6VdhwsFjI1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Open Price"
      ],
      "metadata": {
        "id": "60WfDnQXkJGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open price for a stock refers to the initial price at which a share of a particular company begins trading when the stock market opens for the day. The open price is influenced by various factors, including pre-market trading, the previous day's closing price, overall market sentiment, news and events related to the company or the broader market, and the supply and demand for the stock."
      ],
      "metadata": {
        "id": "Kn82CrXtkLbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### High Price"
      ],
      "metadata": {
        "id": "5JDq3veJrChs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The high price for a stock refers to the highest price at which a share of a particular company has traded during a specific period, such as a trading day, week, month, or year. The high price represents the peak value that investors were willing to pay for the stock during that time frame. "
      ],
      "metadata": {
        "id": "WMDHnw0PrFqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Low Price"
      ],
      "metadata": {
        "id": "ojwYjXSdrI92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low price for a stock refers to the lowest price at which a share of a particular company has traded during a specific period, such as a trading day, week, month, or year. The low price represents the minimum value that investors were willing to pay for the stock during that time frame. This information is often used by traders and investors to analyze price trends, as well as to assess the stock's historical performance and potential support levels in technical analysis. Similar to the high price, the low price is not static and will change as new low prices are reached."
      ],
      "metadata": {
        "id": "TcP1PW40rPij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 12))\n",
        "column = ['Open', 'Close', 'High', 'Low']\n",
        "for i in range(4):\n",
        "  plt.subplot(2, 2, i+1)\n",
        "  plt.plot(df.Date, df[column[i]])\n",
        "  plt.ylabel('Close price')\n",
        "  plt.grid(True)\n",
        "  plt.title(str(column[i]))"
      ],
      "metadata": {
        "id": "Fx4S6RXEjJPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Moving Average"
      ],
      "metadata": {
        "id": "LgTwiWyTBGKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The moving average (MA) is a simple technical analysis tool that smooths out price data by creating a constantly updated average price. The average is taken over a specific period of time, like 10 days, 20 minutes, 30 weeks, or any time period the trader chooses."
      ],
      "metadata": {
        "id": "dhsJOjkRBJI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ma_day = [10, 20, 50]\n",
        "\n",
        "for ma in ma_day:\n",
        "      column_name = f\"MA for {ma} days\"\n",
        "      df[column_name] = df['Close'].rolling(ma).mean()"
      ],
      "metadata": {
        "id": "iKZTjYnpjMdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(df.Date, df[['Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']])\n",
        "plt.legend(['Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days'])\n",
        "plt.ylabel('Close Price')\n",
        "plt.xlabel('Date')\n",
        "plt.grid(True)\n",
        "plt.title('Moving Average for Close Price')"
      ],
      "metadata": {
        "id": "8rjNU9ATBRWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Daily Return"
      ],
      "metadata": {
        "id": "YcDHImgRTW-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now going to analyze the risk of the stock. In order to do so we'll need to take a closer look at the daily changes of the stock, and not just its absolute value. Let's go ahead and use pandas to retrieve teh daily returns for the stock."
      ],
      "metadata": {
        "id": "SWX--8cATZj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Daily Return'] = df['Close'].pct_change()\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(df.Date, df['Daily Return'])\n",
        "plt.ylabel('Percentage Change')\n",
        "plt.xlabel('Date')\n",
        "plt.grid(True)\n",
        "plt.title('Daily Return (% Change)')"
      ],
      "metadata": {
        "id": "zNfRkCJSC_g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**III. Modeling**"
      ],
      "metadata": {
        "id": "VSH4Do07kuop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Data Preparation Before Model"
      ],
      "metadata": {
        "id": "bh4DR0tuZEoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_model = df[[\"Open\", \"High\", \"Low\", \"Volume\", \"Close\"]]"
      ],
      "metadata": {
        "id": "q43E6bAGs2kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_size=int(len(df_model)*0.07)\n",
        "train_df = df_model.loc[0:training_size,]\n",
        "test_df = df_model.loc[training_size:, ]\n",
        "X_train = train_df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
        "y_train = train_df[\"Close\"]\n",
        "X_test = test_df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
        "y_test = test_df[\"Close\"]"
      ],
      "metadata": {
        "id": "hQAxs2VvtpHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 OLS"
      ],
      "metadata": {
        "id": "S1q74jLkkyYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Model"
      ],
      "metadata": {
        "id": "5OoQoAPPfOb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "BtXAgELDkw3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_lr = lr.predict(X_train)\n",
        "y_test_pred_lr = lr.predict(X_test)"
      ],
      "metadata": {
        "id": "KRl7fquGu3aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Evaluation"
      ],
      "metadata": {
        "id": "WH3GlnfOfL4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation metrices RMSE, MSE and MAE**\n",
        "\n",
        "Root Mean Square Error (RMSE), Mean Square Error (MSE) and Mean absolute Error (MAE) are a standard way to measure the error of a model in predicting quantitative data."
      ],
      "metadata": {
        "id": "D-0PAL8FfSSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(y_train,y_train_pred_lr)))\n",
        "print(\"Train data MSE: \", mean_squared_error(y_train,y_train_pred_lr))\n",
        "print(\"Train data MAE: \", mean_absolute_error(y_train,y_train_pred_lr))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(y_test,y_test_pred_lr)))\n",
        "print(\"Test data MSE: \", mean_squared_error(y_test,y_test_pred_lr))\n",
        "print(\"Test data MAE: \", mean_absolute_error(y_test,y_test_pred_lr))"
      ],
      "metadata": {
        "id": "lTpYKLqxejeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between the train and test data metrics is not significant, which is a good sign. This indicates that the model is not overfitting, as the performance on the test set is similar to that on the training set."
      ],
      "metadata": {
        "id": "6jzm9BkThnKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explained Variance Score**\n",
        "\n",
        "\n",
        "Explained variance regression score is an evaluation metric used in regression tasks to measure the proportion of the total variance in the target variable that is explained by the predictive model. It is a useful metric for understanding how well the model captures the underlying structure of the data. It ranges from 0 to 1, with 1 being the best possible score. A score of 1 indicates that the model perfectly explains the variance in the target variable, while a score of 0 indicates that the model does not explain any variance in the target variable."
      ],
      "metadata": {
        "id": "c_5CQv9wfqnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(y_train, y_train_pred_lr))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(y_test, y_test_pred_lr))"
      ],
      "metadata": {
        "id": "HaXpLCfHfrKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The explained variance regression score is quite high for both the train and test data, which indicates that the model maybe is doing a good job of capturing the variance in the target variable (stock price)."
      ],
      "metadata": {
        "id": "MnpHeaYqhoRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R<sup>2</sup> score**\n",
        "\n",
        "The R-squared (R2) score, also known as the coefficient of determination, is a metric used to evaluate the performance of a regression model. It measures the proportion of the variance in the dependent variable (target) that can be explained by the independent variables (predictors) in the model.\n",
        "\n",
        "The R2 score ranges from 0 to 1, with higher values indicating a better fit of the model to the data. An R2 score of 1 indicates that the model explains 100% of the variance in the target variable, while an R2 score of 0 means that the model does not explain any variance in the target variable."
      ],
      "metadata": {
        "id": "pHJ-jn0rgghC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(y_train, y_train_pred_lr))\n",
        "print(\"Test data R2 score:\", r2_score(y_test, y_test_pred_lr))"
      ],
      "metadata": {
        "id": "yxM8DYLWgcOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The R-squared score, which measures the proportion of the total variance in the target variable explained by the model, is also high for both the train and test data. This means that the model is accounting for a large portion of the variability in the stock prices."
      ],
      "metadata": {
        "id": "Mg242_nYhvOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction Visualization**\n",
        "\n",
        "We draw a plot to compare between the original stock close price and predicted close price for test dataset."
      ],
      "metadata": {
        "id": "_GEMs_sJkKTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_plot_lr = df[[\"Date\"]]\n",
        "df_plot_lr = df_plot_lr.loc[training_size:, ]\n",
        "df_plot_lr[\"y_test\"] = y_test\n",
        "df_plot_lr[\"y_test_pred_lr\"] = y_test_pred_lr"
      ],
      "metadata": {
        "id": "uVJTQhSClG-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the actual and predicted close prices\n",
        "plt.plot(df_plot_lr['Date'], df_plot_lr['y_test'], label='Actual Close Price', color='blue')\n",
        "plt.plot(df_plot_lr['Date'], df_plot_lr['y_test_pred_lr'], label='Predicted Close Price', color='orange')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price')\n",
        "plt.title('Actual vs Predicted Close Prices')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7VArtc4ekdG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.3 Summarization"
      ],
      "metadata": {
        "id": "kg1CO6fOiKAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that linear regression gives a very good result overall. **However**, this result is not reliable. Here are some of the key reasons why linear regression might not be a good model for predicting stock prices:\n",
        "\n",
        "1. **Linearity assumption**: Linear regression assumes that the relationship between the independent and dependent variables is linear. However, stock prices are influenced by a multitude of factors, including market sentiment, economic indicators, and company-specific news, which can cause nonlinear relationships between the predictors and stock prices.\n",
        "\n",
        "2. **Independence of observations**: Linear regression assumes that the observations are independent of each other. In the case of stock prices, this is not true, as prices are influenced by past prices and market trends, resulting in a time series data structure with inherent autocorrelation.\n",
        "\n",
        "3. **Constant variance (homoscedasticity)**: Linear regression assumes that the variance of the error terms is constant across all levels of the independent variables. Stock prices are known to exhibit heteroscedasticity, with periods of high volatility followed by periods of low volatility.\n",
        "\n",
        "4. **Normal distribution of errors**: Linear regression assumes that the error terms follow a normal distribution. However, stock prices tend to exhibit non-normal distributions, with heavy tails (kurtosis) and skewness, which violates this assumption."
      ],
      "metadata": {
        "id": "nHV1amV3sdbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Support Vector Regression (SVR)"
      ],
      "metadata": {
        "id": "m6kmDC4RshWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Regression (SVR) is the combination of a Support Vector Machines and Regression."
      ],
      "metadata": {
        "id": "7XVjfwOks_QF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why we choose **Support Vector Regressor**?\n",
        "* Linear Regression does not work for our data because our data has many fluctuations and a linear line of best fit would give poor predictions on stock data. A SVM will not work on our data because we aren’t classifying between two different classes.\n",
        "* With stock data, we are not predicting a class, we are predicting the next value in a series.\n",
        "* Using regression we try to minimize the cost function using something like gradient descent. With SVMs we try to try to draw a hyperplane between 2 different classes. So SVR is the combo of the 2, we try to minimize the error within a certain threshold."
      ],
      "metadata": {
        "id": "2AfbPjBztq32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Data Preparation for SVR"
      ],
      "metadata": {
        "id": "Z0fMYx-_p7fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to predict the stock price using Support Vector Regression. In order to let the model learn more efficiently, we will treat this as a time series question. In other words, our sole x feature will be the close price. Thus, we will redo the data preparation in this section."
      ],
      "metadata": {
        "id": "KAxXyvAiqD6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize Close Price**\n",
        "\n",
        "Normalizing the close price of a stock before implementing a model to predict stock prices is important for several reasons:\n",
        "\n",
        "1. Scale uniformity: Financial data can have a wide range of values, which can lead to inconsistencies in scale when comparing different stocks or other financial instruments. Normalization helps to ensure that all data points are on a similar scale, allowing the model to process and compare them more effectively.\n",
        "\n",
        "2. Improved convergence: Machine learning models, particularly neural networks, often perform better and converge faster when their input features have similar scales. Normalizing the data helps to prevent any single feature from dominating the learning process, which could lead to suboptimal results or slow convergence.\n",
        "\n",
        "3. Comparability: When working with time series, normalizing the close prices enables easier comparison between them. This is particularly useful when you want to analyze or predict trends across different stocks or market sectors.\n",
        "\n",
        "4. Mitigating the impact of outliers: Extreme values or outliers in the data can disproportionately affect the model's predictions. By normalizing the close prices, the influence of outliers is reduced, leading to more robust and accurate predictions."
      ],
      "metadata": {
        "id": "5eL_b3y6u9xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the close price column (replace 'close' with the actual column name in your dataset)\n",
        "close_price = df['Close']\n",
        "\n",
        "# Reshape the close price data\n",
        "close_price = np.array(close_price).reshape(-1, 1)\n",
        "\n",
        "# Initialize the MinMaxScaler with the desired feature range\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Fit and transform the close price data\n",
        "normalized_close_price = scaler.fit_transform(close_price)"
      ],
      "metadata": {
        "id": "HCz3Tr8Tu0SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split into train and test data set**\n",
        "\n",
        "We can't use train_test_split to split the data in the time series model. Instead, we can only split the data sequentially. We use 80% of the data for training, and 20% of the data for testing."
      ],
      "metadata": {
        "id": "hUW4cTSNyx8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_size=int(len(close_price)*0.80)\n",
        "train_df = normalized_close_price[0:training_size,]\n",
        "test_df = normalized_close_price[training_size:, ]\n",
        "print(\"train_df: \", train_df.shape)\n",
        "print(\"test_df: \", test_df.shape)"
      ],
      "metadata": {
        "id": "PxNEqj9zzlpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transform Close price base on Time-series-analysis forecasting requirement**\n",
        "\n",
        "Now, we are going to create x and label features for the model. We will create in this way:\n",
        "\n",
        "**Example**\n",
        "\n",
        "Suppose we have a following sequence of time series data:\n",
        "\n",
        "Sequence: 367, 363, 364, 368, 371, 372, 369, 367, 366\n",
        "\n",
        "Timestamp = 3\n",
        "\n",
        "\\begin{array}{|c|c|} \\hline\n",
        "Train Data & Label\\\\ \\hline\n",
        "367, 363, 364 & 368 \\\\ \\hline\n",
        "363, 364, 368 & 371 \\\\\\hline\n",
        "364, 368, 371 & 372 \\\\ \\hline\n",
        "368, 371, 372 & 369  \\\\ \\hline\n",
        "371, 372, 369 & 367  \\\\ \\hline\n",
        "372, 369, 367 & 366 \\\\ \\hline\n",
        "\\end{array}"
      ],
      "metadata": {
        "id": "o3IoAQWE1TGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX = [dataset[i:(i + time_step), 0] for i in range(len(dataset) - time_step - 1)]\n",
        "    dataY = [dataset[i + time_step, 0] for i in range(len(dataset) - time_step - 1)]\n",
        "    \n",
        "    return np.array(dataX), np.array(dataY)"
      ],
      "metadata": {
        "id": "HME1uwwx44Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_step = 10\n",
        "X_train_ts, y_train_ts = create_dataset(train_df, time_step)\n",
        "X_test_ts, y_test_ts = create_dataset(test_df, time_step)\n",
        "\n",
        "print(\"X_train_ts: \", X_train_ts.shape)\n",
        "print(\"y_train_ts: \", y_train_ts.shape)\n",
        "print(\"X_test_ts: \", X_test_ts.shape)\n",
        "print(\"y_test_ts\", y_test_ts.shape)"
      ],
      "metadata": {
        "id": "MS2hmLzB48gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Base Line Model"
      ],
      "metadata": {
        "id": "X2VypPAF5MY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svr_rbf = SVR(kernel= 'rbf', C= 1e2, gamma= 0.1)\n",
        "svr_rbf.fit(X_train_ts, y_train_ts)"
      ],
      "metadata": {
        "id": "jmMUXh9a5PiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_svr_rbf=svr_rbf.predict(X_train_ts)\n",
        "y_test_pred_svr_rbf=svr_rbf.predict(X_test_ts)"
      ],
      "metadata": {
        "id": "EWzrzDmZ5RKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to original form\n",
        "y_train_pred_svr_rbf = scaler.inverse_transform(y_train_pred_svr_rbf.reshape(-1,1))\n",
        "y_test_pred_svr_rbf = scaler.inverse_transform(y_test_pred_svr_rbf.reshape(-1,1))\n",
        "original_y_train = scaler.inverse_transform(y_train_ts.reshape(-1,1)) \n",
        "original_y_test = scaler.inverse_transform(y_test_ts.reshape(-1,1)) "
      ],
      "metadata": {
        "id": "P-ME8A17802G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2.1 Evaluation (Base Line Model)"
      ],
      "metadata": {
        "id": "g1K36BcU7FLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation metrices RMSE, MSE and MAE**"
      ],
      "metadata": {
        "id": "gx8KoT3Z7JMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,y_train_pred_svr_rbf)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_y_train,y_train_pred_svr_rbf))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_y_train,y_train_pred_svr_rbf))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_y_test,y_test_pred_svr_rbf)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_y_test,y_test_pred_svr_rbf))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_y_test,y_test_pred_svr_rbf))"
      ],
      "metadata": {
        "id": "xxVHL_hqsec6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explained Variance Score**"
      ],
      "metadata": {
        "id": "JyHr8vAw7ar_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(original_y_train, y_train_pred_svr_rbf))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(original_y_test, y_test_pred_svr_rbf))"
      ],
      "metadata": {
        "id": "jFNL1_RtvY03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R<sup>2</sup> score**"
      ],
      "metadata": {
        "id": "y6Xgnvel7mO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_y_train, y_train_pred_svr_rbf))\n",
        "print(\"Test data R2 score:\", r2_score(original_y_test, y_test_pred_svr_rbf))"
      ],
      "metadata": {
        "id": "yRwcb7I6veCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction Visualization**"
      ],
      "metadata": {
        "id": "CFDyWWlV7s06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below was based on the original code of this [Kaggle notenook](https://www.kaggle.com/code/ysthehurricane/advanced-stock-pred-using-svr-rfr-knn-lstm-gru/notebook). However, the code below was improved based on the original one and was organized using function."
      ],
      "metadata": {
        "id": "G77ETwBBVFfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_predictions_plot(closedf, train_predict, test_predict, time_step):\n",
        "    look_back = time_step\n",
        "    trainPredictPlot = np.empty_like(closedf)\n",
        "    trainPredictPlot[:, :] = np.nan\n",
        "    trainPredictPlot[look_back:len(train_predict) + look_back, :] = train_predict\n",
        "\n",
        "    testPredictPlot = np.empty_like(closedf)\n",
        "    testPredictPlot[:, :] = np.nan\n",
        "    testPredictPlot[len(train_predict) + (look_back * 2) + 1:len(closedf) - 1, :] = test_predict\n",
        "\n",
        "    return trainPredictPlot, testPredictPlot\n",
        "\n",
        "def plot_stock_prices(close_stock, closedf, trainPredictPlot, testPredictPlot):\n",
        "    names = cycle(['Original close price', 'Train predicted close price', 'Test predicted close price'])\n",
        "\n",
        "    plotdf = pd.DataFrame({'date': close_stock['Date'],\n",
        "                           'original_close': close_stock['Close'],\n",
        "                           'train_predicted_close': trainPredictPlot.reshape(1, -1)[0].tolist(),\n",
        "                           'test_predicted_close': testPredictPlot.reshape(1, -1)[0].tolist()})\n",
        "\n",
        "    fig = px.line(plotdf, x='date', y=['original_close', 'train_predicted_close', 'test_predicted_close'],\n",
        "                  labels={'value': 'Stock price', 'date': 'Date'})\n",
        "    fig.update_layout(title_text='Comparison between Close Price vs Predicted Close Price',\n",
        "                      plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
        "    fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
        "\n",
        "    fig.update_xaxes(showgrid=False)\n",
        "    fig.update_yaxes(showgrid=False)\n",
        "    fig.show()\n",
        "\n",
        "close_stock = df[[\"Date\", \"Close\"]]\n",
        "trainPredictPlot, testPredictPlot = prepare_predictions_plot(close_price, y_train_pred_svr_rbf, y_test_pred_svr_rbf, 10)\n",
        "plot_stock_prices(close_stock, close_price, trainPredictPlot, testPredictPlot)"
      ],
      "metadata": {
        "id": "e2b6OQMFpmcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 Hyperparameter Tuning: SVR with Grid Search"
      ],
      "metadata": {
        "id": "0t-y-VJekczz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR has several hyperparameters that control its behavior and performance. We will tune 3 parameters in the following section:\n",
        "\n",
        "1. **Kernel**: The kernel function used to transform the input data into a higher-dimensional space. Common choices for the kernel function include 'linear', 'poly', 'rbf' (Radial basis function), and 'sigmoid'. We will fix the kernel to be 'rbf'.\n",
        "\n",
        "2. **C (Cost or Regularization parameter)**: This parameter controls the trade-off between achieving a low training error and a low testing error, i.e., the balance between overfitting and underfitting. A smaller value of C creates a wider margin, which may result in more training errors but better generalization to the test data. A larger value of C creates a narrower margin, which minimizes training errors at the potential cost of poorer generalization.\n",
        "\n",
        "3. **epsilon**: This parameter defines the 'insensitive zone' within which no penalty is associated with errors. It controls the width of the tube around the regression line, inside which errors are not penalized. A larger epsilon value results in a smoother regression function, while a smaller epsilon value results in a more flexible function that may be more prone to overfitting.\n",
        "\n",
        "4. **gamma**: It controls the shape of the decision boundary. A small gamma value will produce a more flexible decision boundary, while a large gamma value will produce a more rigid boundary. "
      ],
      "metadata": {
        "id": "OKTHUf7YlAhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paramters = {\n",
        "        'C':[0.001,0.01,0.1,1,100],\n",
        "        'epsilon': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "        'gamma': [0.01, 0.1, 1, 5, 8, 40]\n",
        "    }"
      ],
      "metadata": {
        "id": "VTkINX_yWPIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gsc = GridSearchCV(\n",
        "        estimator=SVR(kernel='rbf'),\n",
        "        param_grid=paramters,\n",
        "        cv=10,\n",
        "        scoring='neg_mean_squared_error'\n",
        "    )"
      ],
      "metadata": {
        "id": "VNtsvtdDWRTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = gsc.fit(X_train_ts,y_train_ts)"
      ],
      "metadata": {
        "id": "y6MKsFC-W68t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_param = grid_result.best_params_\n",
        "svr_model = SVR(kernel='rbf', C=best_param['C'], epsilon=best_param['epsilon'], gamma=best_param['gamma'])\n",
        "svr_model.fit(X_train_ts, y_train_ts)\n",
        "y_train_pred_svr_rbf_cv=svr_model.predict(X_train_ts)\n",
        "y_test_pred_svr_rbf_cv=svr_model.predict(X_test_ts)"
      ],
      "metadata": {
        "id": "i6Ea9RAiXXlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to original form\n",
        "y_train_pred_svr_rbf_cv = scaler.inverse_transform(y_train_pred_svr_rbf_cv.reshape(-1,1))\n",
        "y_test_pred_svr_rbf_cv = scaler.inverse_transform(y_test_pred_svr_rbf_cv.reshape(-1,1))\n",
        "original_y_train = scaler.inverse_transform(y_train_ts.reshape(-1,1)) \n",
        "original_y_test = scaler.inverse_transform(y_test_ts.reshape(-1,1)) "
      ],
      "metadata": {
        "id": "UqeGk6ew32Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.3.1 Evaluation (Tuned Model)"
      ],
      "metadata": {
        "id": "D5Zlu28m5eUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,y_train_pred_svr_rbf_cv)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_y_train,y_train_pred_svr_rbf_cv))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_y_train,y_train_pred_svr_rbf_cv))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_y_test,y_test_pred_svr_rbf_cv)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_y_test,y_test_pred_svr_rbf_cv))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_y_test,y_test_pred_svr_rbf_cv))"
      ],
      "metadata": {
        "id": "PeAdVZnh34G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(original_y_train, y_train_pred_svr_rbf_cv))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(original_y_test, y_test_pred_svr_rbf_cv))"
      ],
      "metadata": {
        "id": "NYHgo0OI352S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_y_train, y_train_pred_svr_rbf_cv))\n",
        "print(\"Test data R2 score:\", r2_score(original_y_test, y_test_pred_svr_rbf_cv))"
      ],
      "metadata": {
        "id": "I8m2bqdJ5Bxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredictPlot, testPredictPlot = prepare_predictions_plot(close_price, y_train_pred_svr_rbf_cv, y_test_pred_svr_rbf_cv, 10)\n",
        "plot_stock_prices(close_stock, close_price, trainPredictPlot, testPredictPlot)"
      ],
      "metadata": {
        "id": "N_DTmRXD5LOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.5 SVR with Bagging"
      ],
      "metadata": {
        "id": "4RugZuVLQRwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_svr = BaggingRegressor(base_estimator = SVR(kernel='rbf', C=best_param['C'], epsilon=best_param['epsilon'], gamma=best_param['gamma']),n_estimators = 1000, random_state=42)\n",
        "model = bagging_svr.fit(X_train_ts, y_train_ts)\n",
        "y_train_pred_bag_svr = model.predict(X_train_ts)\n",
        "y_test_pred_bag_svr = model.predict(X_test_ts)"
      ],
      "metadata": {
        "id": "s_ZfVSeBNWpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to original form\n",
        "y_train_pred_bag_svr = scaler.inverse_transform(y_train_pred_bag_svr.reshape(-1,1))\n",
        "y_test_pred_bag_svr = scaler.inverse_transform(y_test_pred_bag_svr.reshape(-1,1))\n",
        "original_y_train = scaler.inverse_transform(y_train_ts.reshape(-1,1)) \n",
        "original_y_test = scaler.inverse_transform(y_test_ts.reshape(-1,1))"
      ],
      "metadata": {
        "id": "m8hI72e8Odmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.5.1 Evaluation (Bagging SVR)"
      ],
      "metadata": {
        "id": "V6ox6EkPQbRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,y_train_pred_bag_svr)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_y_train,y_train_pred_bag_svr))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_y_train,y_train_pred_bag_svr))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_y_test,y_test_pred_bag_svr)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_y_test,y_test_pred_bag_svr))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_y_test,y_test_pred_bag_svr))"
      ],
      "metadata": {
        "id": "fyW2bixvOnQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(original_y_train, y_train_pred_bag_svr))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(original_y_test, y_test_pred_bag_svr))"
      ],
      "metadata": {
        "id": "hqn3sVYdQfDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_y_train, y_train_pred_bag_svr))\n",
        "print(\"Test data R2 score:\", r2_score(original_y_test, y_test_pred_bag_svr))"
      ],
      "metadata": {
        "id": "P2-KiuxlQm7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredictPlot, testPredictPlot = prepare_predictions_plot(close_price, y_train_pred_bag_svr, y_test_pred_bag_svr, 10)\n",
        "plot_stock_prices(close_stock, close_price, trainPredictPlot, testPredictPlot)"
      ],
      "metadata": {
        "id": "mwTCRct2Qz23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Decision Tree Regressor"
      ],
      "metadata": {
        "id": "VfTfqC2XSwDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree Regressor can model complex relationships between input features and the target variable (in this case, stock prices) by recursively partitioning the data into subsets based on the values of the input features.\n",
        "\n",
        "However, Decision Trees have some limitations when applied to time series data like stock prices. Decision Trees are not inherently designed to capture temporal dependencies present in time series data. To account for time dependencies, we will perform feature engineering that capture the historical information, such as lagged values or moving averages of the stock prices before building the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "RTPa99NEWy7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1 Feature Engineering"
      ],
      "metadata": {
        "id": "wwqZ3tWWXGhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will perform feature engineering to create additional features that capture relevant information from the time series data.\n",
        "\n",
        "1. **Lagged values**: Create lagged features by shifting the close prices by different time steps (e.g., 1 day, 3 days). This captures the historical price information, which can help the model learn how past prices influence future prices.\n",
        "\n",
        "2. **Moving averages**: Calculate simple moving averages (SMA) or exponential moving averages (EMA) of the close prices over different time windows (e.g., 5 days, 10 days, 30 days). Moving averages help smoothen the time series and capture trends in the data.\n",
        "\n",
        "3. **Price change**: Compute the percentage change in close prices over different periods (e.g., daily, weekly, monthly). This feature can help the model capture the momentum and volatility of the stock price.\n",
        "\n",
        "4. **Date-based features**: Extract features from the date, such as day of the week, day of the month, month, and quarter. These features can help the model capture any seasonality or cyclic patterns present in the stock price."
      ],
      "metadata": {
        "id": "HUfC1dX9dnWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dt = df[[\"Close\", \"Open\", \"High\", \"Low\", \"Volume\"]]"
      ],
      "metadata": {
        "id": "e5oNVPjIZGGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lagged values\n",
        "df_dt['lag_3'] = df_dt['Close'].shift(3)\n",
        "\n",
        "# Calculate moving averages\n",
        "df_dt['SMA_3'] = df_dt['Close'].rolling(window=3).mean()\n",
        "\n",
        "# Calculate price change\n",
        "df_dt['price_change'] = df_dt['Close'].diff()\n",
        "\n",
        "# Add date-based features\n",
        "df_dt['day_of_week'] = df['Date'].dt.dayofweek\n",
        "df_dt['day_of_month'] = df['Date'].dt.day\n",
        "df_dt['month'] = df['Date'].dt.month\n",
        "df_dt['quarter'] = df['Date'].dt.quarter\n",
        "\n",
        "# Remove rows with missing values caused by the shift and rolling operations\n",
        "df_dt = df_dt.dropna()"
      ],
      "metadata": {
        "id": "S0PQAYKLZJGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the correlation between x variables."
      ],
      "metadata": {
        "id": "9l0hIoqogEmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dt.corr()"
      ],
      "metadata": {
        "id": "Niff6JidcYr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we see that there are high correlations between features Open, High, and Low, so we decide to drop these 3 features."
      ],
      "metadata": {
        "id": "1OooebfGixHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dt = df_dt.drop([\"High\", \"Low\", \"Open\"], axis =1)"
      ],
      "metadata": {
        "id": "5Smv6gCii7xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.2 Base Line Decision Tree Model"
      ],
      "metadata": {
        "id": "u-6nCK6_eViP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_dt.loc[:, df_dt.columns != \"Close\"]\n",
        "y = df_dt['Close']\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "oN2Yxg6reVKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Decision Tree Regressor\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "dt_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2wP979DijWzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_train_pred_dt = dt_regressor.predict(X_train)\n",
        "y_test_pred_dt = dt_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "jrzRe__ajZOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3.2.1 Evaluation (Base Line DT Model)"
      ],
      "metadata": {
        "id": "XHRVPr5Hj5jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(y_train,y_train_pred_dt)))\n",
        "print(\"Train data MSE: \", mean_squared_error(y_train,y_train_pred_dt))\n",
        "print(\"Train data MAE: \", mean_absolute_error(y_train,y_train_pred_dt))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(y_test,y_test_pred_dt)))\n",
        "print(\"Test data MSE: \", mean_squared_error(y_test,y_test_pred_dt))\n",
        "print(\"Test data MAE: \", mean_absolute_error(y_test,y_test_pred_dt))"
      ],
      "metadata": {
        "id": "D8CIe0n2ZSrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(y_train, y_train_pred_dt))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(y_test, y_test_pred_dt))"
      ],
      "metadata": {
        "id": "xLOqvYvlkjZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(y_train, y_train_pred_dt))\n",
        "print(\"Test data R2 score:\", r2_score(y_test, y_test_pred_dt))"
      ],
      "metadata": {
        "id": "Iq4I6PxJkpjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of the Decision Tree Regressor model show a clear sign of overfitting. The training error metrics (RMSE, MSE, and MAE) are all 0, and the R2 score and explained variance regression score for the training data are both 1.0, which means the model has perfectly fit the training data. However, this perfection is not reflected in the test data results.\n",
        "\n",
        "The test data error metrics (RMSE, MSE, and MAE) are significantly higher than those for the training data. Although the R2 score and explained variance regression score for the test data are relatively high (0.9526), the significant difference in performance between the training and test sets indicates that the model is overfitting to the training data and not generalizing well to new, unseen data.\n",
        "\n",
        "To mitigate overfitting, we will consider the following approaches:\n",
        "\n",
        "1. **Prune the decision tree**: Limit the depth of the tree, set a minimum number of samples required to split a node, or set a minimum number of samples required at a leaf node. These constraints can help make the tree less complex and more generalizable.\n",
        "\n",
        "2. **Use cross-validation**: K-fold cross-validation can help you assess the model's performance more accurately and detect overfitting.\n",
        "\n",
        "3. **Ensemble methods**: Combine multiple decision trees using methods like Random Forest or Gradient Boosting to reduce the likelihood of overfitting and improve the model's performance."
      ],
      "metadata": {
        "id": "S-alvkHKlX_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.3 Decision Tree with Pruning"
      ],
      "metadata": {
        "id": "ZA7zjqS_m61t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-pruning is nothing but stopping the growth of the decision tree at an early stage. For that, we can limit the growth of trees by setting constraints. We can limit parameters like `max_depth`, `min_samples_split`, etc.\n",
        "\n",
        "An effective way to do this is that we can grid search those parameters and choose the optimum values that give better performance on test data.\n",
        "\n",
        "As of now, we will control these parameters\n",
        "\n",
        "`max_depth`: maximum depth of decision tree\n",
        "\n",
        "`min_sample_split`: The minimum number of samples required to split an internal node:\n",
        "\n",
        "`min_samples_leaf`: The minimum number of samples required to be at a leaf node."
      ],
      "metadata": {
        "id": "VhWjKQSQnIWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'max_depth': [4,8,12],\n",
        "         'min_samples_split': [4,6,8,10],\n",
        "         'min_samples_leaf': [3,5,7,9,11]}\n",
        "\n",
        "clf = DecisionTreeRegressor(random_state=42)\n",
        "gcv = GridSearchCV(estimator=clf,param_grid=params)\n",
        "gcv.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "zB-Ss1S5nCrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcv.best_estimator_"
      ],
      "metadata": {
        "id": "fULOSzCrnXbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gcv.best_estimator_\n",
        "model.fit(X_train,y_train)\n",
        "y_train_pred_dt_prune = model.predict(X_train)\n",
        "y_test_pred_dt_prune = model.predict(X_test)\n",
        "print(\"Depth: \"+ str(model.tree_.max_depth)) #number of split levels\n",
        "print(\"Leaves: \"+ str(model.tree_.n_leaves))\n",
        "fig = plt.figure(figsize=(50,45))\n",
        "tree.plot_tree(model, feature_names = X_train.columns, filled=True, max_depth=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tZqv-HFrnm3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3.3.1 Evaluation (Pruned DT Model)"
      ],
      "metadata": {
        "id": "ksEwfs6in9nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(y_train,y_train_pred_dt_prune)))\n",
        "print(\"Train data MSE: \", mean_squared_error(y_train,y_train_pred_dt_prune))\n",
        "print(\"Train data MAE: \", mean_absolute_error(y_train,y_train_pred_dt_prune))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(y_test,y_test_pred_dt_prune)))\n",
        "print(\"Test data MSE: \", mean_squared_error(y_test,y_test_pred_dt_prune))\n",
        "print(\"Test data MAE: \", mean_absolute_error(y_test,y_test_pred_dt_prune))"
      ],
      "metadata": {
        "id": "-WpxKTXIoFR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(y_train, y_train_pred_dt_prune))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(y_test, y_test_pred_dt_prune))"
      ],
      "metadata": {
        "id": "4tVM-MOQoFJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(y_train, y_train_pred_dt_prune))\n",
        "print(\"Test data R2 score:\", r2_score(y_test, y_test_pred_dt_prune))"
      ],
      "metadata": {
        "id": "5orWuO9woE98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Random Forest Regressor"
      ],
      "metadata": {
        "id": "DCGTUYTcqfOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4.1 Base Line RFR"
      ],
      "metadata": {
        "id": "0k7C07JEqwh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators = 500, max_depth = 50, random_state = 42)\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Pmtxjo3CqeYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_rf = rf.predict(X_train)\n",
        "y_test_pred_rf = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "y8NYJIy9rUin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4.1.1 Evaluation (Base RFR)"
      ],
      "metadata": {
        "id": "Y-kTpRp7rkzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(y_train,y_train_pred_rf)))\n",
        "print(\"Train data MSE: \", mean_squared_error(y_train,y_train_pred_rf))\n",
        "print(\"Train data MAE: \", mean_absolute_error(y_train,y_train_pred_rf))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(y_test,y_test_pred_rf)))\n",
        "print(\"Test data MSE: \", mean_squared_error(y_test,y_test_pred_rf))\n",
        "print(\"Test data MAE: \", mean_absolute_error(y_test,y_test_pred_rf))"
      ],
      "metadata": {
        "id": "TjPqEUbBrqd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(y_train, y_train_pred_rf))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(y_test, y_test_pred_rf))"
      ],
      "metadata": {
        "id": "nqXZPGEIrs0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(y_train, y_train_pred_rf))\n",
        "print(\"Test data R2 score:\", r2_score(y_test, y_test_pred_rf))"
      ],
      "metadata": {
        "id": "U-4vfOhhruqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4.2 RFR Based on Time Series Data"
      ],
      "metadata": {
        "id": "Mf8O56Qrv41I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_ts = RandomForestRegressor(n_estimators = 500, max_depth = 50, random_state = 42)\n",
        "rf_ts.fit(X_train_ts, y_train_ts)"
      ],
      "metadata": {
        "id": "dCNlMnDzv-Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_rf_ts = rf_ts.predict(X_train_ts)\n",
        "y_test_pred_rf_ts = rf_ts.predict(X_test_ts)"
      ],
      "metadata": {
        "id": "NPGph5fRwEpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to original form\n",
        "y_train_pred_rf_ts = scaler.inverse_transform(y_train_pred_rf_ts.reshape(-1,1))\n",
        "y_test_pred_rf_ts = scaler.inverse_transform(y_test_pred_rf_ts.reshape(-1,1))\n",
        "original_y_train = scaler.inverse_transform(y_train_ts.reshape(-1,1)) \n",
        "original_y_test = scaler.inverse_transform(y_test_ts.reshape(-1,1)) "
      ],
      "metadata": {
        "id": "cKbY0v76xPiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4.2.1 Evaluation (Time Series RFR Model)"
      ],
      "metadata": {
        "id": "eElktuwfwqp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,y_train_pred_rf_ts)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_y_train,y_train_pred_rf_ts))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_y_train,y_train_pred_rf_ts))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_y_test,y_test_pred_rf_ts)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_y_test,y_test_pred_rf_ts))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_y_test,y_test_pred_rf_ts))"
      ],
      "metadata": {
        "id": "bR_ltgafwrOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(original_y_train, y_train_pred_rf_ts))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(original_y_test, y_test_pred_rf_ts))"
      ],
      "metadata": {
        "id": "GTUkZ0mIwrlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_y_train, y_train_pred_rf_ts))\n",
        "print(\"Test data R2 score:\", r2_score(original_y_test, y_test_pred_rf_ts))"
      ],
      "metadata": {
        "id": "FYwem_vJwr9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 LSTM"
      ],
      "metadata": {
        "id": "aXNnNEJrTGUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5.1 Baseline LSTM"
      ],
      "metadata": {
        "id": "ixi5zrcK_poL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model=Sequential()\n",
        "model.add(LSTM(32,return_sequences=True,input_shape=(time_step,1)))\n",
        "model.add(LSTM(32,return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')"
      ],
      "metadata": {
        "id": "JnO0cv41TubB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "snsARzAeT1jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_ts,y_train_ts,validation_data=(X_train_ts,y_train_ts),epochs=200,batch_size=5,verbose=1)"
      ],
      "metadata": {
        "id": "73Px_IToT_yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Lets Do the prediction and check performance metrics\n",
        "train_predict_lstm=model.predict(X_train_ts)\n",
        "test_predict_lstm=model.predict(X_test_ts)\n",
        "train_predict_lstm.shape, test_predict_lstm.shape"
      ],
      "metadata": {
        "id": "2WG5GKOVUAdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to original form\n",
        "train_predict_lstm = scaler.inverse_transform(train_predict_lstm.reshape(-1,1))\n",
        "test_predict_lstm = scaler.inverse_transform(test_predict_lstm.reshape(-1,1))\n",
        "original_y_train = scaler.inverse_transform(y_train_ts.reshape(-1,1)) \n",
        "original_y_test = scaler.inverse_transform(y_test_ts.reshape(-1,1)) "
      ],
      "metadata": {
        "id": "moIaa7NuUHqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,train_predict_lstm)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_y_train,train_predict_lstm))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_y_train,train_predict_lstm))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_y_test,test_predict_lstm)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_y_test,test_predict_lstm))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_y_test,test_predict_lstm))"
      ],
      "metadata": {
        "id": "oU9tXI4uXlwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(original_y_train, train_predict_lstm))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(original_y_test, test_predict_lstm))"
      ],
      "metadata": {
        "id": "ledqBOSVX33H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_y_train, train_predict_lstm))\n",
        "print(\"Test data R2 score:\", r2_score(original_y_test, test_predict_lstm))"
      ],
      "metadata": {
        "id": "wsmWJPfyYJFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredictPlot, testPredictPlot = prepare_predictions_plot(close_price, train_predict_lstm, test_predict_lstm, 10)\n",
        "plot_stock_prices(close_stock, close_price, trainPredictPlot, testPredictPlot)"
      ],
      "metadata": {
        "id": "PmDVon8nYrN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5.2 Hyperparameter Tuning LSTM"
      ],
      "metadata": {
        "id": "bvN4ZuKN_lcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
        "                   return_sequences=True,\n",
        "                   input_shape=(X_train_ts.shape[1], 1)))\n",
        "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32)))\n",
        "    model.add(Dense(units=1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "v843tiD05eD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3)"
      ],
      "metadata": {
        "id": "x-i0uBm65pXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train_ts, y_train_ts, epochs=10, validation_data=(X_train_ts, y_train_ts))\n"
      ],
      "metadata": {
        "id": "J9vBYxDu5wpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = build_model(best_hps)\n",
        "model.fit(X_train_ts, y_train_ts, epochs=200, validation_data=(X_train_ts, y_train_ts))\n"
      ],
      "metadata": {
        "id": "7KrpZmyC6OnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Lets Do the prediction and check performance metrics\n",
        "train_predict_lstm_tuned=model.predict(X_train_ts)\n",
        "test_predict_lstm_tuned=model.predict(X_test_ts)\n",
        "train_predict_lstm_tuned.shape, test_predict_lstm_tuned.shape"
      ],
      "metadata": {
        "id": "qKiWVXFs6-yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to original form\n",
        "train_predict_lstm_tuned = scaler.inverse_transform(train_predict_lstm_tuned.reshape(-1,1))\n",
        "test_predict_lstm_tuned = scaler.inverse_transform(test_predict_lstm_tuned.reshape(-1,1))\n",
        "original_y_train = scaler.inverse_transform(y_train_ts.reshape(-1,1)) \n",
        "original_y_test = scaler.inverse_transform(y_test_ts.reshape(-1,1)) "
      ],
      "metadata": {
        "id": "x3tGUDMV6-qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,train_predict_lstm)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_y_train,train_predict_lstm))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_y_train,train_predict_lstm))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_y_test,test_predict_lstm)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_y_test,test_predict_lstm))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_y_test,test_predict_lstm))"
      ],
      "metadata": {
        "id": "Wwlajeer7OIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(original_y_train, train_predict_lstm_tuned))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(original_y_test, test_predict_lstm_tuned))"
      ],
      "metadata": {
        "id": "uxp-Mji57O3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_y_train, train_predict_lstm_tuned))\n",
        "print(\"Test data R2 score:\", r2_score(original_y_test, test_predict_lstm_tuned))"
      ],
      "metadata": {
        "id": "9jqWP4Oy7OwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6 GRU"
      ],
      "metadata": {
        "id": "buy53_SrY0Er"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6.1 Baseline GRU"
      ],
      "metadata": {
        "id": "Z6MCbFxvAYLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model=Sequential()\n",
        "model.add(GRU(32,return_sequences=True,input_shape=(time_step,1)))\n",
        "model.add(GRU(32,return_sequences=True))\n",
        "model.add(GRU(32,return_sequences=True))\n",
        "model.add(GRU(32))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')"
      ],
      "metadata": {
        "id": "k0TUJ0i1ZByP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "T4gzRaZMZCiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_ts,y_train_ts,validation_data=(X_train_ts,y_train_ts),epochs=200,batch_size=5,verbose=1)"
      ],
      "metadata": {
        "id": "CFrbOERiZGBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Lets Do the prediction and check performance metrics\n",
        "train_predict=model.predict(X_train_ts)\n",
        "test_predict=model.predict(X_test_ts)\n",
        "train_predict.shape, test_predict.shape"
      ],
      "metadata": {
        "id": "0Urt-GEDZJLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to original form\n",
        "train_predict_gru = scaler.inverse_transform(train_predict.reshape(-1,1))\n",
        "test_predict_gru = scaler.inverse_transform(test_predict.reshape(-1,1))\n",
        "original_y_train = scaler.inverse_transform(y_train_ts.reshape(-1,1)) \n",
        "original_y_test = scaler.inverse_transform(y_test_ts.reshape(-1,1)) "
      ],
      "metadata": {
        "id": "YTSVF_GzZOEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,train_predict_gru)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_y_train,train_predict_gru))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_y_train,train_predict_gru))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_y_test,test_predict_gru)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_y_test,test_predict_gru))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_y_test,test_predict_gru))"
      ],
      "metadata": {
        "id": "W6A1nKo__9XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(original_y_train, train_predict_gru))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(original_y_test, test_predict_gru))"
      ],
      "metadata": {
        "id": "akeTb0pAAHBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_y_train, train_predict_gru))\n",
        "print(\"Test data R2 score:\", r2_score(original_y_test, test_predict_gru))"
      ],
      "metadata": {
        "id": "ML3f7myJAHb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6.2 Hyperparameter Tuning GRU"
      ],
      "metadata": {
        "id": "fXiGEfW9AcUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "tf.keras.backend.clear_session()\n",
        "# define the GRU model architecture\n",
        "def build_model(units=32):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(units=units, return_sequences=True, input_shape=(X_train_ts.shape[1], 1)))\n",
        "    model.add(GRU(units=units))\n",
        "    model.add(Dense(units=1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# create a KerasRegressor wrapper for the model\n",
        "keras_reg = KerasRegressor(build_fn=build_model, verbose=0)\n",
        "\n",
        "# define the hyperparameters to search over\n",
        "param_dist = {\n",
        "    'units': sp_randint(32, 512),\n",
        "    'batch_size': sp_randint(32, 128),\n",
        "    'epochs': sp_randint(50, 200)\n",
        "}\n",
        "\n",
        "# perform Random Search using cross-validation to find the best hyperparameters\n",
        "search = RandomizedSearchCV(keras_reg, param_distributions=param_dist, n_iter=5, cv=3, error_score='raise')\n",
        "search_results = search.fit(X_train_ts, y_train_ts)\n",
        "\n",
        "# get the best hyperparameters and fit the model with them\n",
        "best_params = search_results.best_params_\n",
        "model = build_model(units=best_params['units'])\n",
        "model.fit(X_train_ts, y_train_ts, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "score = model.evaluate(X_test_ts, y_test_ts, verbose=0)\n",
        "print('Test loss:', score)"
      ],
      "metadata": {
        "id": "21QB-uyoBZs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Lets Do the prediction and check performance metrics\n",
        "train_predict=model.predict(X_train_ts)\n",
        "test_predict=model.predict(X_test_ts)\n",
        "train_predict.shape, test_predict.shape"
      ],
      "metadata": {
        "id": "88nHIX8dEcZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to original form\n",
        "train_predict_gru_tuned = scaler.inverse_transform(train_predict.reshape(-1,1))\n",
        "test_predict_gru_tuned = scaler.inverse_transform(test_predict.reshape(-1,1))\n",
        "original_y_train = scaler.inverse_transform(y_train_ts.reshape(-1,1)) \n",
        "original_y_test = scaler.inverse_transform(y_test_ts.reshape(-1,1))"
      ],
      "metadata": {
        "id": "UI6dJBobEs7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrices RMSE and MAE\n",
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,train_predict_gru_tuned)))\n",
        "print(\"Train data MSE: \", mean_squared_error(original_y_train,train_predict_gru_tuned))\n",
        "print(\"Train data MAE: \", mean_absolute_error(original_y_train,train_predict_gru_tuned))\n",
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_y_test,test_predict_gru_tuned)))\n",
        "print(\"Test data MSE: \", mean_squared_error(original_y_test,test_predict_gru_tuned))\n",
        "print(\"Test data MAE: \", mean_absolute_error(original_y_test,test_predict_gru_tuned))"
      ],
      "metadata": {
        "id": "ysOb--c5Ey5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data explained variance regression score:\", explained_variance_score(original_y_train, train_predict_gru_tuned))\n",
        "print(\"Test data explained variance regression score:\", explained_variance_score(original_y_test, test_predict_gru_tuned))"
      ],
      "metadata": {
        "id": "LZAEu04EE6Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data R2 score:\", r2_score(original_y_train, train_predict_gru_tuned))\n",
        "print(\"Test data R2 score:\", r2_score(original_y_test, test_predict_gru_tuned))"
      ],
      "metadata": {
        "id": "ilMQoakDE-97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 ARIMA"
      ],
      "metadata": {
        "id": "FIdYCdl8VXO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arima = df[[\"Date\", \"Close\"]]\n",
        "df_arima.set_index(['Date'],inplace=True)\n",
        "df_arima.head()"
      ],
      "metadata": {
        "id": "9VJbL5IHvvM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Plotting the data"
      ],
      "metadata": {
        "id": "7ULvESdOWkVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arima.plot(figsize=(20,5))\n",
        "plt.ylabel('Close')\n",
        "plt.title('Close Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5e6kV_2KVfkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Checking for stationarity using Augmented Dickey Fuller Test"
      ],
      "metadata": {
        "id": "ovrLHddEWz9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "def adfuller_test(trends):\n",
        "    result = adfuller(trends)\n",
        "    labels = ['ADF Test Statistic','p-value','#Lags Used','#Observation Used']\n",
        "    for value,label in zip(result,labels):\n",
        "        print(label  + ': ' + str(value))\n",
        "    if result[1]<=0.05:\n",
        "        print('Strong evidence against the null hypothesis, Hence REJECT Ho. and The series is Stationary')\n",
        "    else:\n",
        "        print('week evidence against null hypothesis, Hence ACCEPT Ho. that the series is not stationary.')\n",
        "        \n",
        "adfuller_test(df_arima['Close'])"
      ],
      "metadata": {
        "id": "nTOlGMMuWhju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 Differencing Data ==> Make it stationary"
      ],
      "metadata": {
        "id": "gaw2Kr3_XE8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff1=df_arima-df_arima.shift(1)\n",
        "diff1=diff1.dropna()\n",
        "adfuller_test(diff1)\n",
        "diff1.plot(figsize=(20,5))"
      ],
      "metadata": {
        "id": "QeoIHywMW_EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is now stationary and the order of differencing is 1."
      ],
      "metadata": {
        "id": "hY5lwbWsXT44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4 Plotting Autocorrelation and Partial Autocorreltion functions"
      ],
      "metadata": {
        "id": "mMRxfDQWXXoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "sgt.plot_acf(diff1['Close'], ax=ax, lags=30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KAUveBsHXO-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.5 Model Implementation"
      ],
      "metadata": {
        "id": "mq2Jz7zCdFix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Use the 'Close' column as the target variable\n",
        "price = df['Close']\n",
        "# price=price-price.shift(1)\n",
        "# price=price.dropna()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(len(price) * 0.8)\n",
        "train, test = price[:train_size], price[train_size:]\n",
        "\n",
        "# Fit the ARIMA model\n",
        "p, d, q = 3,1,5\n",
        "model = ARIMA(train, order=(p, d, q))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_fit.forecast(steps=len(test))\n",
        "predictions\n",
        "\n",
        "# Plot the actual and predicted stock prices\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test.index, test)\n",
        "plt.plot(predictions)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Close Price\")\n",
        "plt.legend(['Actual', 'Prediction'])"
      ],
      "metadata": {
        "id": "wS6oeGG6QNF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-------------------------------------------------------------------------------------\")\n",
        "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(test, predictions)))\n",
        "print(\"Test data MSE: \", mean_squared_error(test, predictions))\n",
        "print(\"Test data MAE: \", mean_absolute_error(test, predictions))"
      ],
      "metadata": {
        "id": "3Q8ngfzOSlYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test data explained variance regression score:\", explained_variance_score(test, predictions))"
      ],
      "metadata": {
        "id": "wIk9G4gJUHhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test data R2 score:\", r2_score(test, predictions))"
      ],
      "metadata": {
        "id": "ti6qn1ZrUTIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_y_train,y_train_pred_rf_ts)))"
      ],
      "metadata": {
        "id": "pP3FqNhjUaXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T96esp30gfR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}